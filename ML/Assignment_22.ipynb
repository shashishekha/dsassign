{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e794c0c",
   "metadata": {},
   "source": [
    "### 1. Is there any way to combine five different models that have all been trained on the same training\n",
    "### data and have all achieved 95 percent precision? If so, how can you go about doing it? If not, what is\n",
    "### the reason?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe075c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cf04c59",
   "metadata": {},
   "source": [
    "### 2. What&#39;s the difference between hard voting classifiers and soft voting classifiers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45103016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dd8fe88",
   "metadata": {},
   "source": [
    "### 3. Is it possible to distribute a bagging ensemble&#39;s training through several servers to speed up the\n",
    "### process? Pasting ensembles, boosting ensembles, Random Forests, and stacking ensembles are all\n",
    "### options.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7f848b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80ad5543",
   "metadata": {},
   "source": [
    "### 4. What is the advantage of evaluating out of the bag?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a5b708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "938890d4",
   "metadata": {},
   "source": [
    "### 5. What distinguishes Extra-Trees from ordinary Random Forests? What good would this extra\n",
    "### randomness do? Is it true that Extra-Tree Random Forests are slower or faster than normal Random\n",
    "### Forests?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9f6132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3bed622",
   "metadata": {},
   "source": [
    "### 6. Which hyperparameters and how do you tweak if your AdaBoost ensemble underfits the training\n",
    "### data?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a325ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d1f8af1",
   "metadata": {},
   "source": [
    "### 7. Should you raise or decrease the learning rate if your Gradient Boosting ensemble overfits the\n",
    "### training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5313b5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
